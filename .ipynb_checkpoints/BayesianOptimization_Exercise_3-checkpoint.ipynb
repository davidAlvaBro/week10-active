{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "PwjpxE0TxXwW",
    "outputId": "55e74243-2692-4c51-b5fb-38d1994e9492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\david\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\david\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install ipynb\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, distributions\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O39lIiQGxXwq"
   },
   "source": [
    "# Bayesian Optimization from scratch\n",
    "\n",
    "In the last lecture we have seen how to use Gaussian Process for regression.In this lecture we are going to see how to use them for an optimization problem. \n",
    "\n",
    "The general setting of an optimization problem is that we have a certain objective function $f(x)$ that we want to maximize. Mathematicallly, we are interested in\n",
    "\n",
    "$$x^{*} = \\arg \\max_{x \\in X} f(x)$$\n",
    "\n",
    "where $X$ is often a compact subset of $\\mathbb{R}$. We consider a particular case of optimization problem: we have no analytical expression for the function of our interest $f$ and we cannot also compute the gradient with respect of $x$. Therefore we cannot use usual methods like gradient ascent (or gradient descent on $-f(x)$) to find the maximum. We are assuming a *black box* function $f$, that means, we can only evaluate the function at any query point $x$ in the domain. In other words we can observe the function $f$ only through unbiased and noisy observations $y$. In addition to that, evaluating the unknown function is expensive, either in term of computation or time, and we have only a limited budget.\n",
    "\n",
    "In the lecture, we have seen that when we are dealing with these kinds of functions, Bayesian Optimization is a powerful sequential strategy to find the maximum/minimum. It has two main ingredients:\n",
    "\n",
    "1. A probabilistic model over functions\n",
    "2. An acquisition function\n",
    "\n",
    "As probabilistic model, we are going to use a Gaussian Process. We need two functions, that you have also seen in the previous exercise session. One function `fit_predictive_gp` that fits the Gaussian Process and one function `optimize_gp_hyperparameters` that finds the value of lengthscale, output variance, and noise variance that maximize the log-likelihood plus the log prior. Since this step would be a repetition of the previous exercise session, we will provide these functions (with comments) for you. We are also providing the code for the dataset of the last lecture to show you that the functions works.\n",
    "\n",
    "<font color='blue'> Tasks:\n",
    "\n",
    "1. You should implement a function that fit a Gaussian Process (following the algorithm you have learnt last lecture) `fit_predictive_GP(X, y, Xtest, lengthscale, kernel_variance, noise_variance)` (you should also reimplement the squared exponential kernel).  <font color='Green'>( Note that we are already giving you a function that optimizes the hyperparameters of the kernel. It is done in PyTorch using Gradient Descent. Also note, that this is is not the way that the Bayesian Optimization library implements this.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCYwG3P2xXwx"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-10d30c90f45c>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-10d30c90f45c>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    sqdist =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def squared_exponential_kernel(x, y, lengthscale, variance):\n",
    "    '''\n",
    "    Function that computes the covariance matrix using a squared-exponential kernel\n",
    "    '''\n",
    "    # pair-wise distances, size: NxM\n",
    "    sqdist = \n",
    "    # compute the kernel\n",
    "    cov_matrix =   # NxM\n",
    "    return cov_matrix\n",
    "\n",
    "\n",
    "def fit_predictive_GP(X, y, Xtest, lengthscale, kernel_variance, noise_variance):\n",
    "    '''\n",
    "    Function that fit the Gaussian Process. It returns the predictive mean function and\n",
    "    the predictive covariance function. It follows step by step the algorithm on the lecture\n",
    "    notes\n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "    return mu, covariance\n",
    "\n",
    "\n",
    "# I am using PyTorch to define the optimization function, it can be done in different other ways.\n",
    "# It is not the best way to implement it, I suppose\n",
    "def optimize_GP_hyperparams(Xtrain, ytrain, optimization_steps, learning_rate, mean_prior, prior_std):\n",
    "    '''\n",
    "    Methods that run the otpimization of the hyperparams of our GP. We will use\n",
    "    Gradient Descent because it takes to much time to run grid search at each step\n",
    "    of bayesian optimization. We use a different definition of the kernel to make the\n",
    "    optimization more stable\n",
    "\n",
    "    :param X: training set points\n",
    "    :param y: training targets\n",
    "    :return: values for lengthscale, output_var, noise_var that maximize the log-likelihood\n",
    "    '''\n",
    "    \n",
    "    # we are re-defining the kernel because we need it in PyTorch\n",
    "    def squared_exponential_kernel_torch(x, y, _lambda, variance):\n",
    "        x = x.squeeze(1).expand(x.size(0), y.size(0))\n",
    "        y = y.squeeze(0).expand(x.size(0), y.size(0))\n",
    "        sqdist = torch.pow(x - y, 2)\n",
    "        k = variance * torch.exp(-0.5 * sqdist * (1/_lambda**2))  # NxM\n",
    "        return k\n",
    "\n",
    "    X = np.array(Xtrain).reshape(-1,1)\n",
    "    y = np.array(ytrain).reshape(-1,1)\n",
    "    N = len(X)\n",
    "\n",
    "    # tranform our training set in Tensor\n",
    "    Xtrain_tensor = torch.from_numpy(X).float()\n",
    "    ytrain_tensor = torch.from_numpy(y ).float()\n",
    "    # we should define our hyperparameters as torch parameters where we keep track of\n",
    "    # the operations to get hte gradients from them\n",
    "    _lambda = nn.Parameter(torch.tensor(1.), requires_grad=True)\n",
    "    output_variance = nn.Parameter(torch.tensor(1.), requires_grad=True)\n",
    "    noise_variance = nn.Parameter(torch.tensor(.5), requires_grad=True)\n",
    "\n",
    "    # we use Adam as optimizer\n",
    "    optim = torch.optim.Adam([_lambda, output_variance, noise_variance], lr=learning_rate)\n",
    "\n",
    "    # optimization loop using the log-likelihood that involves the cholesky decomposition \n",
    "    nlls = []\n",
    "    lambdas = []\n",
    "    output_variances = []\n",
    "    noise_variances = []\n",
    "    iterations = optimization_steps\n",
    "    for i in range(iterations):\n",
    "        assert noise_variance >= 0, f\"ouch! {i, noise_variance}\"\n",
    "        optim.zero_grad()\n",
    "        K = squared_exponential_kernel_torch(Xtrain_tensor, Xtrain_tensor, _lambda,\n",
    "                                                output_variance) + noise_variance * torch.eye(N)\n",
    "        \n",
    "        L = torch.cholesky(K)\n",
    "        _alpha_temp, _ = torch.solve(ytrain_tensor, L)\n",
    "        _alpha, _ = torch.solve(_alpha_temp, L.t())\n",
    "        nll = N / 2 * torch.log(torch.tensor(2 * np.pi)) + 0.5 * torch.matmul(ytrain_tensor.transpose(0, 1),\n",
    "                                                                              _alpha) + torch.sum(torch.log(torch.diag(L)))\n",
    "\n",
    "        # we have to add the log-likelihood of the prior\n",
    "        norm = distributions.Normal(loc=mean_prior, scale=prior_std)\n",
    "        prior_negloglike =  torch.log(_lambda) - torch.log(torch.exp(norm.log_prob(_lambda)))\n",
    "\n",
    "        nll += 0.9 * prior_negloglike\n",
    "        nll.backward()\n",
    "\n",
    "        nlls.append(nll.item())\n",
    "        lambdas.append(_lambda.item())\n",
    "        output_variances.append(output_variance.item())\n",
    "        noise_variances.append(noise_variance.item())\n",
    "        optim.step()\n",
    "\n",
    "        # projected in the constraints (lengthscale and output variance should be positive)\n",
    "        for p in [_lambda, output_variance]:\n",
    "            p.data.clamp_(min=0.0000001)\n",
    "\n",
    "        noise_variance.data.clamp_(min=1e-5, max= 0.05)\n",
    "\n",
    "        \n",
    "    return _lambda.item(), output_variance.item(), noise_variance.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCFanOzWAknR"
   },
   "source": [
    "<font color='Blue'> Task:\n",
    "1. Here you check if you Gaussian Process regression algotihm works as expected. (Note, we are giving the parameters of the prior of the lengthscale. If you need clarification in how we are optimizing the kernel parameters, feel free to ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "colab_type": "code",
    "id": "DdZNto37xXw5",
    "outputId": "a6507fbc-c8f6-4cd1-81a7-75dd7b71eee6"
   },
   "outputs": [],
   "source": [
    "## safety check: we try to run the code in the dataset of last lecture and see if it works\n",
    "from scipy.io import loadmat\n",
    "\n",
    "## We load the data and use only some of them.\n",
    "## We subsample the data, which gives us N pairs of (x, y)\n",
    "M = 1000\n",
    "data = loadmat('weather_dataset.mat')\n",
    "# sampling part \n",
    "Xtrain = np.arange(0, M, 20)\n",
    "ytrain = data['TMPMAX'][Xtrain]\n",
    "N = len(ytrain)\n",
    "Xtrain = Xtrain.reshape(-1,1)\n",
    "\n",
    "# print dataset information\n",
    "print('Xtrain shape', Xtrain.shape)\n",
    "print('ytrain shape', ytrain.shape)\n",
    "\n",
    "# also in this case we standardize the data to have zero mean and unit variance\n",
    "Xtrain = (Xtrain - np.mean(Xtrain)) / np.std(Xtrain)\n",
    "ytrain = (ytrain - np.mean(ytrain)) / np.std(ytrain)\n",
    "\n",
    "# and plot it\n",
    "plt.plot(Xtrain, ytrain, 'o', color='black')\n",
    "plt.ylabel('Normalized level of precipitations')\n",
    "plt.xlabel('Time')\n",
    "plt.show()\n",
    "\n",
    "# we shall also define the test set, that is the range of XTest point we want to \n",
    "# use to compute the mean and the variance\n",
    "Xtest = np.linspace(-2, 2, M).reshape(-1,1)\n",
    "\n",
    "## we have to define the mena and variance of the log-normal distribution for the lengthscale prior \n",
    "prior_mean = -1.5\n",
    "prior_std = 0.6\n",
    "\n",
    "lengthscale, output_var, noise_var = optimize_GP_hyperparams(Xtrain, ytrain, 500, 5e-3, prior_mean, prior_std)\n",
    "print('Optimized parameters:', lengthscale, output_var, noise_var)\n",
    "\n",
    "# we can fit the GP that use the hyperparameters found above\n",
    "mu, covariance = fit_predictive_GP(Xtrain, ytrain, Xtest, lengthscale, output_var, noise_var)\n",
    "std = np.sqrt(np.diag(covariance))\n",
    "plt.plot(Xtrain, ytrain, 'ro', label='Training points')\n",
    "plt.gca().fill_between(Xtest.flat, mu.reshape(-1) - 2 * std, mu.reshape(-1) + 2 * std,  color='lightblue', alpha=0.5, label=r\"$\\mu$\")\n",
    "plt.plot(Xtest, mu, 'blue', label=r\"$2\\sigma$\")\n",
    "plt.legend()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APuEpZl4xXxB"
   },
   "source": [
    "## Acquisition Function\n",
    "\n",
    "The second key ingredient of Bayesian Optimization are **acquisition functions**. These auxiliary functions uses the information from the probabilistic model to trade off exploration and exploitation. Indeed, the next point where we are going to query the unknown objective function is the one that maximize the acquisition function. \n",
    "\n",
    "We have seen three different functions in the lecture: *Probability of Improvement*, *Expected Improvement*, and *Upper Confidence Bound*. We are going to repeat their formulation here.\n",
    "\n",
    "### Probability of improvement\n",
    "\n",
    "The probability of improvement try to measure for each point $x \\in \\mathcal{X}$, where $\\mathcal{X}$ is our space of interest, the probability that $f(x)$ is higher than the current best sample $f(x^+)$. \n",
    "\n",
    "The mathematica formulation is given by:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{PI}(\\mathbf{x}) &= \\text{P}(f(\\mathbf{x}) \\geq f(\\mathbf{x}^+) + \\xi) = \\\\\n",
    "               &= \\Phi\\biggl(\\frac{\\mu(\\mathbf{x}) - f(\\mathbf{x}^+) - \\xi}{\\sigma(\\mathbf{x})}\\biggr)\n",
    "\\end{align}\n",
    "\n",
    "where $\\xi$ is an hyperparameter left to the user, that trades off exploration and exploitation and $\\Phi$ is the cumulative distribution function of the Gaussian distribution.\n",
    "\n",
    "### Expected improvement\n",
    "\n",
    "Expected improvement tries to quantify the amount of improvement for each  $x \\in \\mathcal{X}$ with respect the current best sample. Using a Gaussian Process as probabilistic model, this is given by:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{EI}(\\mathbf{x}) = \\left\\{\n",
    "\\begin{array}{>{\\displaystyle\\tallstrut}l@{}}\n",
    "(\\mu(\\mathbf{x}) - f(\\mathbf{x}^+)) \\Phi(Z) + \\sigma(\\mathbf{x})  \\phi(Z) \\hspace{1.66cm} \\text{if } \\sigma(\\mathbf{x}) > 0\\\\ \n",
    "0  \\hspace{7.38cm} \\text{if } \\sigma(\\mathbf{x}) > 0\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{align}\n",
    "\n",
    "where $Z = \\frac{\\mu(\\mathbf{x}) - f(\\mathbf{x}^+) - \\xi }{\\sigma(\\mathbf{x})}$ and $\\Phi$ is the cumulative distribution function and $\\phi$ the probability density function of the standard Gaussian distribution.\n",
    "\n",
    "\n",
    "### Gaussian Process Upper Confidence Bound\n",
    "\n",
    "The Gaussian Process - Upper Confidence bound (GP-UCB) trades off exploration and exploration by using directly the predictive mean and variance from the Gaussian Process. While its first formulation is pretty easy\n",
    "\n",
    "\\begin{align}\n",
    "\\text{UCB}(\\mathbf{x}) = \\mu(\\mathbf{x}) + \\kappa \\sigma (\\mathbf{x})\n",
    "\\end{align}\n",
    "\n",
    "where $\\kappa$ is the trade-off parameters we have to choose beforehand, in recent publication a new formulation has been considered. Additionally, it has been proven for specific parameters, the new formulation leads to no regret asymptotically, which means that it gets the true maximum of the function. For this reason, we are going to implement the new formulation, which is defined as:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{GP-UCB}(\\mathbf{x}) = \\mu(\\mathbf{x}) + \\sqrt{\\nu \\beta_t} \\sigma (\\mathbf{x})\n",
    "\\end{align}\n",
    "\n",
    "where $\\beta_t$ depends on the iteration $t$ and $\\nu$ is left to the user. It has been proven that with $\\nu = 1$ and $\\beta_t = 2 \\log(\\frac{t^{\\frac{d}{2}+2}\\pi^2}{3 \\delta})$,where $t$ is the iteration number, $d$ is the dimensionality of the problem, and $\\delta \\leq 0$ is left to the user, we would have *no-regret* asymptotically.\n",
    "\n",
    "A simple approximation, is given by: \n",
    "\n",
    "\\begin{align}\n",
    "\\text{GP-UCB}(\\mathbf{x}) = \\mu(\\mathbf{x}) + \\epsilon \\log(t) \\sigma (\\mathbf{x})\n",
    "\\end{align}\n",
    "\n",
    "<font color='blue'> Tasks:\n",
    "1. Implement the three different acquisition functions in Python.\n",
    "2. We provide you some points, try to fit a Gaussian Process on this points (remember to optimize the hyperparameters first), and compute the acquisition function. Code is provided to plot both the GP and the different acquisition functions. Try to understand what happens when you change the value of the trade-off hyperparameter $\\xi$ or $\\nu$ (or $\\epsilon$). To help you with this plots with varying values of the hyperparameter are provided in the same plot.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7Uj2se7xXxE"
   },
   "outputs": [],
   "source": [
    "# we want to define the function over all the points in the\n",
    "# range of interest, defined as X\n",
    "def probability_of_improvement(current_best, mean, std, eps):\n",
    "    '''\n",
    "    Thus function implements the probability of improvement acquisition function.\n",
    "    It implements\n",
    "        PI(x) = P(f(x) >= f(x^+))\n",
    "            since we consider f(x^+) = mu^+ + eps we have\n",
    "              = Phi ( (mu - mu^+ - eps) / sigma )\n",
    "    :param current_best: this is the current max of the unknown function: mu^+\n",
    "    :param mean: this is the mean function from the GP over the considered set of points\n",
    "    :param std: this is the std function from the GP over the considered set of points\n",
    "    :param eps: small value added to avoid corner case\n",
    "    :return: the value of this acquisition function for all the points\n",
    "    '''\n",
    "    # since std coan be 0, to avoid an error, we add a small value in the denominator (like +1e-9)\n",
    "    PI = \n",
    "    return PI \n",
    "\n",
    "\n",
    "def expected_improvement(current_best, mean, std, eps):\n",
    "    '''\n",
    "    It implements the following function:\n",
    "\n",
    "            | (mu - mu^+ - eps) Phi(Z) + sigma phi(Z) if sigma > 0\n",
    "    EI(x) = |\n",
    "            | 0                                       if sigma = 0\n",
    "\n",
    "            where Phi is the CDF and phi the PDF of the normal distribution\n",
    "            and\n",
    "            Z = (mu - mu^+ - eps) / sigma\n",
    "\n",
    "    :param current_best: this is the current max of the unknown function: mu^+\n",
    "    :param mean: this is the mean function from the GP over the considered set of points\n",
    "    :param std: this is the std function from the GP over the considered set of points\n",
    "    :param eps: small value added to avoid corner case\n",
    "    :return: the value of this acquisition function for all the points\n",
    "    '''\n",
    "\n",
    "    # start by computing the Z as we did in the probability of improvement function\n",
    "    # to avoid division by 0, add a small term eg. np.spacing(1e6) to the denominator\n",
    "\n",
    "    # now we have to compute the output only for the terms that have their std > 0\n",
    "    \n",
    "    return EI\n",
    "\n",
    "\n",
    "def GP_UCB(mean, std, t, dim = 1.0, v = 1.0, delta = .1):\n",
    "    '''\n",
    "    Implementation of the Gaussian Process - Upper Confident Bound:\n",
    "        GP-UBC(x) = mu + sqrt(v * beta) * sigma\n",
    "\n",
    "    where we are usinv v = 1 and beta = 2 log( t^(d/2 + 2) pi^2 / 3 delta)\n",
    "    as proved in Srinivas et al, 2010, to have 0 regret.\n",
    "\n",
    "    :param mean: this is the mean function from the GP over the considered set of points\n",
    "    :param std: this is the std function from the GP over the considered set of points\n",
    "    :param t: iteration number\n",
    "    :param dim: dimension of the input space\n",
    "    :param v: hyperparameter that weights the beta for the exploration-exploitation trade-off. If v = 1 and another\n",
    "              condition, it is proved we have 0 regret\n",
    "    :param delta: hyperparameter used in the computation of beta\n",
    "    :return: the value of this acquisition function for all the points\n",
    "    '''\n",
    "    beta = \n",
    "    UCB = \n",
    "    return UCB\n",
    "\n",
    "\n",
    "\n",
    "def GP_UCB_approx(mean, std, t, eps):\n",
    "    '''\n",
    "    Implementation of the Gaussian Process - Upper Confident Bound in a easy approximate way:\n",
    "        GP-UBC(x) = mu + eps * log(t) * sigma\n",
    "\n",
    "    we use the fact that beta ~ log(t)^2, so we have sqrt(v * log(t)^2) = log(t)*sqrt(v) ~ eps * log(t)\n",
    "\n",
    "    :param mean: this is the mean function from the GP over the considered set of points\n",
    "    :param std: this is the std function from the GP over the considered set of points\n",
    "    :param t: iteration number\n",
    "    :param eps: trade-off constant\n",
    "    :return: the value of this acquisition function for all the points\n",
    "    '''\n",
    "    UCB = \n",
    "    return UCB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "rVsRJNlcxXxM",
    "outputId": "0568800c-9836-403a-e27a-4124bd1528ec"
   },
   "outputs": [],
   "source": [
    "### testing example\n",
    "# create toy dataset\n",
    "\n",
    "# space of interest\n",
    "xs = np.linspace(0,1,100)\n",
    "\n",
    "X_samples = [0.16, 0.2, 0.67, 0.85]\n",
    "#y_samples = [6.2, 6.5, 7.9, 9] # if you divide those by 10 it does not work!\n",
    "y_samples = [7.2, 5.4, 8.7, 7.6]\n",
    "## plot the dataset\n",
    "plt.plot(X_samples, y_samples, 'o', color='black')\n",
    "plt.xlim(0.,1.)\n",
    "plt.ylim(-5.,15)\n",
    "\n",
    "## prior for the lengthscale\n",
    "prior_mean = -2\n",
    "prior_std = 0.6\n",
    "\n",
    "lengthscale, output_var, noise_var = optimize_GP_hyperparams(X_samples, y_samples, 1000, 5e-3, prior_mean, prior_std)\n",
    "print(lengthscale, output_var, noise_var)\n",
    "\n",
    "# we can fit the GP that use the hyperparameters found above\n",
    "mu, covariance = fit_predictive_GP(X_samples, y_samples, xs, lengthscale, output_var, noise_var)\n",
    "std = np.sqrt(np.diag(covariance))\n",
    "plt.plot(X_samples, y_samples, 'ro', label='Training points')\n",
    "plt.gca().fill_between(xs.flat, mu.reshape(-1) - 2 * std, mu.reshape(-1) + 2 * std,  color='lightblue', alpha=0.5, label=r\"$\\mu$\")\n",
    "plt.plot(xs, mu, 'blue', label=r\"$2\\sigma$\")\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "\n",
    "current_best = np.max(y_samples)\n",
    "t = len(X_samples) + 1 \n",
    "## compute the acquisition functions\n",
    "## probability of improvement\n",
    "acquisition_values1 = probability_of_improvement(current_best,  mu, std, 0.01)\n",
    "next_x1 = np.argmax(acquisition_values1)\n",
    "acquisition_values2 = probability_of_improvement(current_best,  mu, std, 0.1)\n",
    "next_x2 = np.argmax(acquisition_values2)\n",
    "acquisition_values3 = probability_of_improvement(current_best,  mu, std, 1)\n",
    "next_x3 = np.argmax(acquisition_values3)\n",
    "\n",
    "# plot them\n",
    "plt.plot(xs, acquisition_values1, '-', color='blue', label =r'$\\xi = 0.01$')\n",
    "plt.plot(xs[next_x1], acquisition_values1[next_x1], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values2, '-', color='green', label =r'$\\xi = 0.1$')\n",
    "plt.plot(xs[next_x2], acquisition_values2[next_x2], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values3, '-', color='red', label =r'$\\xi = 1.$')\n",
    "plt.plot(xs[next_x3], acquisition_values3[next_x3], 'v', color='orange', label='Next $x$ to be evaluted')\n",
    "plt.title('Probability of Improvement')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## expected_improvement\n",
    "acquisition_values1 = expected_improvement(current_best,  mu, std, 0.01)\n",
    "next_x1 = np.argmax(acquisition_values1)\n",
    "acquisition_values2 = expected_improvement(current_best,  mu, std, 0.1)\n",
    "next_x2 = np.argmax(acquisition_values2)\n",
    "acquisition_values3 = expected_improvement(current_best,  mu, std, 1)\n",
    "next_x3 = np.argmax(acquisition_values3)\n",
    "\n",
    "# plot them\n",
    "plt.plot(xs, acquisition_values1, '-', color='blue', label =r'$\\xi = 0.01$')\n",
    "plt.plot(xs[next_x1], acquisition_values1[next_x1], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values2, '-', color='green', label =r'$\\xi = 0.1$')\n",
    "plt.plot(xs[next_x2], acquisition_values2[next_x2], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values3, '-', color='red', label =r'$\\xi = 1.$')\n",
    "plt.plot(xs[next_x3], acquisition_values3[next_x3], 'v', color='orange', label='Next $x$ to be evaluted')\n",
    "plt.title('Expected Improvement')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## GP-UCB approximate and no-regret\n",
    "acquisition_values1 = GP_UCB_approx(mu, std, t, 0.01)\n",
    "next_x1 = np.argmax(acquisition_values1)\n",
    "acquisition_values2 = GP_UCB_approx(mu, std, t, 0.1)\n",
    "next_x2 = np.argmax(acquisition_values2)\n",
    "acquisition_values3 = GP_UCB_approx(mu, std, t, 1)\n",
    "next_x3 = np.argmax(acquisition_values3)\n",
    "\n",
    "acquisition_values_no_regret = GP_UCB(mu, std, t)\n",
    "next_x_no_regret = np.argmax(acquisition_values_no_regret)\n",
    "\n",
    "# plot them\n",
    "plt.plot(xs, acquisition_values1, '-', color='blue', label =r'$\\xi = 0.01$')\n",
    "plt.plot(xs[next_x1], acquisition_values1[next_x1], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values2, '-', color='green', label =r'$\\xi = 0.1$')\n",
    "plt.plot(xs[next_x2], acquisition_values2[next_x2], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values3, '-', color='red', label =r'$\\xi = 1.$')\n",
    "plt.plot(xs[next_x3], acquisition_values3[next_x3], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values_no_regret, '-', color='purple', label =r'No-regret formulation')\n",
    "plt.plot(xs[next_x_no_regret], acquisition_values_no_regret[next_x_no_regret], 'v', color='orange', label='Next $x$ to be evaluted')\n",
    "plt.title('GP-UCB approximation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## GP-UCB original formulation\n",
    "acquisition_values1 = GP_UCB_original( mu, std, 0.01)\n",
    "next_x1 = np.argmax(acquisition_values1)\n",
    "acquisition_values2 = GP_UCB_original(  mu, std, 0.1)\n",
    "next_x2 = np.argmax(acquisition_values2)\n",
    "acquisition_values3 = GP_UCB_original(  mu, std, 1)\n",
    "next_x3 = np.argmax(acquisition_values3)\n",
    "\n",
    "# plot them\n",
    "plt.plot(xs, acquisition_values1, '-', color='blue', label =r'$\\xi = 0.01$')\n",
    "plt.plot(xs[next_x1], acquisition_values1[next_x1], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values2, '-', color='green', label =r'$\\xi = 0.1$')\n",
    "plt.plot(xs[next_x2], acquisition_values2[next_x2], 'v', color='orange')\n",
    "plt.plot(xs, acquisition_values3, '-', color='red', label =r'$\\xi = 1.$')\n",
    "plt.plot(xs[next_x3], acquisition_values3[next_x3], 'v', color='orange', label='Next $x$ to be evaluted')\n",
    "plt.title('UBC-original formulation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JSRx51A_xXxS"
   },
   "source": [
    "### Put everything together\n",
    "\n",
    "At this point you master both ingredients of Bayesian Optimization. In the last part of the previous exercise, you learned how to execute a single iteration of Bayesian Optimization. Therefore, repeating this step for $T$ times, would create the sequence strategy to find the maximum of an unknown objective function. \n",
    "\n",
    "We are going to simulate scenario in which you should maximize an unknown function using Bayesian Optimization.\n",
    "\n",
    "<font color='blue'> Tasks:\n",
    "1. We will give you a black box objective function that you want to maximize. You have to implement the Bayesian Optimization loop to perform the sequential search. At each step you should plot both the GP and the acquisition function. As in a real Bayesian Optimization setting, you do not have the mathematical formulation of the objective function. You only know that it is defined in $[0,2]$, ans you can query it using the followiong function `query_the_objective(x)`, which get as input the point $x \\in \\mathcal{X}$ that has to be evaluated. In addition to that, it has also a function to plot the real function, but you should use it only at the end, which is `plot_the_unknown_function()`. To compare the result you obtain, you can ask the \"true\" max by calling the function `get_the_true_max()`, which return both the value of $x$ and of $f(x)$. Notice that we test the algorithm with `np.random.seed(32)`. Sometimes BO gets stuck in local minima, therefore you should try to run it again using a different value for the trade-off parameter $\\xi$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5UmLET9gxXxU",
    "outputId": "c2c969de-14d7-4108-e1a7-37c4147528ec"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5ed5a43e5440>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-5ed5a43e5440>\"\u001b[1;36m, line \u001b[1;32m42\u001b[0m\n\u001b[1;33m    lengthscale, output_variance, noise_variance =\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.unknown_objective import query_the_objective, plot_the_unknown_function, get_the_true_max \n",
    "np.random.seed(32)\n",
    "# points that we are considering\n",
    "X = np.linspace(0,2,200)\n",
    "\n",
    "# prior over the lengthscale\n",
    "prior_mean = -1.5 \n",
    "priot_std = 0.6\n",
    "\n",
    "# array for the points x' and repective f(x') that we sample using the acquisition function\n",
    "X_sample = []\n",
    "y_sample = []\n",
    "\n",
    "# number of iterations\n",
    "T = 15\n",
    "\n",
    "# number of initial random samples\n",
    "init_samples = 6\n",
    "\n",
    "# trade-off hyperparams\n",
    "eps = 0.5\n",
    "\n",
    "# get some random samples\n",
    "for _ in range(init_samples):\n",
    "    # sample a point at random\n",
    "    xt = X[np.random.randint(0, len(X))]\n",
    "    # evaluate the point\n",
    "    X_sample.append(xt)\n",
    "    # we query the function\n",
    "    y_sample.append(query_the_objective(xt))\n",
    "    \n",
    "    \n",
    "# bayesian optimization loop\n",
    "# compute the current best \n",
    "current_best = np.max(y_sample)\n",
    "\n",
    "# loop\n",
    "\n",
    "for t in range(len(X_sample),len(X_sample) + T):\n",
    "    ## we should optimize the GP hyperparameters before fitting the final GP and computing the acquisition\n",
    "    ## functions\n",
    "    lengthscale, output_variance, noise_variance =\n",
    "    print(lengthscale, output_variance, noise_variance)\n",
    "    # we have to fit the GP using the X_sample, Y_sample and our training point\n",
    "    mu, covariance =\n",
    "    # get the standard deviation\n",
    "    std = \n",
    "\n",
    "    ## calculate acquisition values for your acquisition function of choice\n",
    "    acquisition_values = \n",
    "    \n",
    "    # we have to find the xt that maximizes this acquisition function\n",
    "    xt = X[np.argmax(acquisition_values)]\n",
    "\n",
    "\n",
    "    ## now we should create the plots\n",
    "    if t > 0:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        fig, axs = plt.subplots(2)\n",
    "        fig.suptitle(f't = {t}')\n",
    "        axs[0].fill_between(X.flat, mu - std, mu + std,  color='lightblue', alpha=0.5, label = r\"$\\sigma$\")\n",
    "        # axs[0].fill_between(X.flat, mu - noise_, mu + noise_, color='red', alpha=0.4, label=r\"predictive\")\n",
    "        axs[0].plot(X, mu, 'b-', label=r'$\\mu$')\n",
    "\n",
    "        if len(X_sample) > 0:\n",
    "            axs[0].plot(X_sample, y_sample, 'bo', label='Sampled points')\n",
    "        axs[0].plot(xt, query_the_objective(xt), 'yo', label='Next sampled point')\n",
    "        axs[0].legend()\n",
    "\n",
    "        #plot acquisition\n",
    "        axs[1].plot(X, acquisition_values, '-', color = 'green', label = 'acquisition function')\n",
    "        axs[1].axvline(xt, color = 'red', linestyle = '--', label='Position of the next x evaluated')\n",
    "        axs[1].legend()\n",
    "        plt.show()\n",
    "\n",
    "    # we compute the value of xt and we add xt and f(xt) in X_samples and y_samples\n",
    "    X_sample.append(xt)\n",
    "    # we append a noisy observation (should we?)\n",
    "    y_sample.append(query_the_objective(xt))\n",
    "\n",
    "    # update current best\n",
    "    current_best = np.max(y_sample)\n",
    "    \n",
    "    \n",
    "print('\\n Candidates for the maximum of the function are:')\n",
    "print(\"X's: \", X_sample)\n",
    "print(\"Respective y's: \", y_sample)\n",
    "print('--------------')\n",
    "print('The max of the function found by the algorithm is: ', np.max(y_sample))\n",
    "get_the_true_max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "ZZWCyx48xXxb",
    "outputId": "945bb23e-4d07-46fe-bdaf-9efc42c1609a"
   },
   "outputs": [],
   "source": [
    "plot_the_unknown_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBOfBkI1xXxh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "collapsed_sections": [],
   "name": "Lecture_2_Exercise_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
